{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "sys.path.append(\"../impl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data, test_classifier\n",
    "from preprocess import preprocess, ordered_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../impl/final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "my_dataset = preprocess(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset_df = pd.DataFrame.from_dict(my_dataset, orient=\"index\")\n",
    "my_dataset_df.replace('NaN', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclude = [\"poi\", \"email_address\"]\n",
    "all_features_list = [f for f in my_dataset.items()[0][1].keys() if f not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list_org = ['poi'] + ordered_columns + [\"to_messages\", \"from_messages\", \"from_this_person_to_poi\", \n",
    "                                                \"shared_receipt_with_poi\", \"from_poi_to_this_person\"]\n",
    "features_list_ext = features_list_org + [\"to_poi_perc\", \"from_poi_perc\", \"shared_with_poi_perc\"]\n",
    "features_list_full = [\"poi\"] + all_features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump cleaned dataset and features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../impl/dev/my_dataset.pkl\", \"w\") as dataset_outfile:\n",
    "        pickle.dump(my_dataset, dataset_outfile)\n",
    "\n",
    "with open(\"../impl/dev/features_list_org.pkl\", \"w\") as featurelist_outfile:\n",
    "        pickle.dump(features_list_org, featurelist_outfile)\n",
    "with open(\"../impl/dev/features_list_ext.pkl\", \"w\") as featurelist_outfile:\n",
    "        pickle.dump(features_list_ext, featurelist_outfile)\n",
    "with open(\"../impl/dev/features_list_full.pkl\", \"w\") as featurelist_outfile:\n",
    "        pickle.dump(features_list_full, featurelist_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.feature_selection import  SelectPercentile, mutual_info_classif, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = features_list_org\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def constructNB(base_clf=None, param=None): \n",
    "    \"\"\"\n",
    "    Construct Naive Bayes classifier, define default construction proccess\n",
    "    and deafault grid search setup \n",
    "    \"\"\"    \n",
    "    \n",
    "    if not base_clf:\n",
    "        base_clf = Pipeline([\n",
    "                    ('feature_selection', SelectPercentile()),\n",
    "                    ('classification', GaussianNB())\n",
    "                  ])\n",
    "    if not param:\n",
    "        param = {\n",
    "            \"feature_selection__score_func\" : [f_classif, mutual_info_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            }\n",
    "    \n",
    "    clf = GridSearchCV(base_clf,\n",
    "                    param_grid = param,\n",
    "                    scoring = make_scorer(f1_score),\n",
    "                    cv = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=32))\n",
    "    return clf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_v1 = constructNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_or_fit(clf, features, labels, path, dump_new=True, features_path=None):\n",
    "    \"\"\"\n",
    "    Load dumped version of classifier from provided path.\n",
    "    Otherwise fit classifier, if dump_new is True, then dump it in a provided path.\n",
    "    If features_path is specified, than dump current features_list to the features_path\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open(path, \"r\") as clf_infile:\n",
    "            fitted_clf = pickle.load(clf_infile)\n",
    "        print \"Classifier was loaded from \", path\n",
    "    except IOError:\n",
    "        print \"Failed to load fitted classifier\\nStart fitting...\"\n",
    "        t0 = time()\n",
    "        fitted_clf = clf\n",
    "        fitted_clf.fit(features, labels)\n",
    "        print \"Classifier fitted in \", round(time()-t0, 3), \"s\"\n",
    "        if dump_new:\n",
    "            with open(path, \"w\") as clf_outfile:\n",
    "                pickle.dump(fitted_clf, clf_outfile)\n",
    "            print \"Fitted classifier was dumped to \", path\n",
    "        \n",
    "    if features_path:\n",
    "        with open(features_path, \"w\") as feat_outfile:\n",
    "            pickle.dump(features_list, feat_outfile)\n",
    "    \n",
    "    return fitted_clf \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_clf(clf, my_dataset, features_list, n_splits=100, random_state=32, test_size=0.2):\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for train_index, test_index in sss.split(features, labels):\n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_index:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_index:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        clf.fit(features_train, labels_train)\n",
    "        pred = clf.predict(features_test)\n",
    "        accuracy_list.append(accuracy_score(labels_test, pred))\n",
    "        precision_list.append(precision_score(labels_test, pred))\n",
    "        recall_list.append(recall_score(labels_test, pred))\n",
    "        f1_list.append(f1_score(labels_test, pred))\n",
    "\n",
    "    return np.mean(accuracy_list), np.mean(precision_list), np.mean(recall_list), \\\n",
    "            np.mean(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_summary(fname, values, version):\n",
    "    with open(fname, \"a\") as f:\n",
    "        #if empty add header\n",
    "        if f.tell() == 0: \n",
    "            f.write(\"Version, Accuracy, Precision, Recall, F1\\n\")\n",
    "        line = version + \", %2.4f\"*4 % values + \"\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v1 = load_or_fit(clf_v1, features, labels, path=\"../impl/dev/clf_v1.pkl\", \n",
    "                     features_path = \"../impl/dev/features_list_org.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=100, random_state=32, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('feature_selection', SelectPercentile(percentile=10,\n",
       "         score_func=<function f_classif at 0x117394a28>)), ('classification', GaussianNB(priors=None))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'feature_selection__score_func': [<function f_classif at 0x117394a28>, <function mutual_info_classif at 0x11752e938>], 'feature_selection__percentile': [30, 50, 70, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(f1_score), verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_selection__percentile': 70,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33256631930161346"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score correspond to best F1 value. Next some other scores are presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.831034482759, Precision: 0.411264041514, Recall: 0.3375, F1: 0.332566319302\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v1.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver1(NB)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentile</th>\n",
       "      <th>score</th>\n",
       "      <th>score_fun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>&lt;function f_classif at 0x117394a28&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.203847</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x11752e938&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.316916</td>\n",
       "      <td>&lt;function f_classif at 0x117394a28&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.241352</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x11752e938&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0.332566</td>\n",
       "      <td>&lt;function f_classif at 0x117394a28&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>0.285572</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x11752e938&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.329348</td>\n",
       "      <td>&lt;function f_classif at 0x117394a28&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>0.329348</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x11752e938&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  percentile     score                                      score_fun\n",
       "0         30  0.303232            <function f_classif at 0x117394a28>\n",
       "1         30  0.203847  <function mutual_info_classif at 0x11752e938>\n",
       "2         50  0.316916            <function f_classif at 0x117394a28>\n",
       "3         50  0.241352  <function mutual_info_classif at 0x11752e938>\n",
       "4         70  0.332566            <function f_classif at 0x117394a28>\n",
       "5         70  0.285572  <function mutual_info_classif at 0x11752e938>\n",
       "6        100  0.329348            <function f_classif at 0x117394a28>\n",
       "7        100  0.329348  <function mutual_info_classif at 0x11752e938>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "{ \"score\" : clf_v1.cv_results_[\"mean_test_score\"], \n",
    "\"percentile\" : clf_v1.cv_results_[\"param_feature_selection__percentile\"],\n",
    "\"score_fun\" : clf_v1.cv_results_['param_feature_selection__score_func']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features were used by NB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exercised_stock_options', 24.815079733218194),\n",
       " ('total_stock_value', 24.182898678566879),\n",
       " ('bonus', 20.792252047181535),\n",
       " ('salary', 18.289684043404513),\n",
       " ('deferred_income', 11.458476579280369)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, pval = f_classif(features, labels)\n",
    "l = zip(features_list_org[1:], f)\n",
    "n_features = int(round(0.3*len(l)))\n",
    "sorted(l, key = lambda s: s[1], reverse=True )[:n_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that NB classifier assumes that featues are independent, however we have included total payments and total stock values along with their constitution. Next we we run NB on reduced set of features and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_list = [feat for feat in features_list_org if feat not in [\"total_payments\", \"total_stock_value\"]]\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "clf_v12 = constructNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v12.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v12 = load_or_fit(clf_v12, features, labels, \"../impl/dev/clf_v12.pkl\", \"dev/features_reduced.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters\n",
      "{'feature_selection__score_func': <function f_classif at 0x117394a28>, 'feature_selection__percentile': 70}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best test score\n",
      "0.347924703023\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print \"Optimal parameters\\n{}\\n{}\".format(clf_v12.best_params_, \"-\"*100)\n",
    "print \"Best test score\\n{}\\n{}\".format(clf_v12.best_score_, \"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding correlated features did not change test score, however, we can notice that this time already 70% of features were included in the model. In next section we will try to resrtucture current features or add some new features in order to provide more information for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808965517241, Precision: 0.397204517705, Recall: 0.395, F1: 0.347924703023\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v12.best_estimator_, my_dataset, \n",
    "                                                       features_list)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver12(NB)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for now, Naive Bayes gives nearly 0.35 test score. Both variants have variance and recall higher than 0.3.\n",
    "The second classifier has higher recall - 0.42."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list_org, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructDT(base_clf=None, param=None): \n",
    "    \"\"\"\n",
    "    Construct Naive Bayes classifier, define default construction proccess\n",
    "    and deafault grid search setup \n",
    "    \"\"\"    \n",
    "    \n",
    "    if not base_clf:\n",
    "        base_clf = Pipeline([\n",
    "                    ('feature_selection', SelectPercentile()),\n",
    "                    ('classification', DecisionTreeClassifier(class_weight=\"balanced\"))\n",
    "                  ])\n",
    "    if not param:\n",
    "        param = {\n",
    "            \"feature_selection__score_func\" : [f_classif, mutual_info_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            \"classification__min_samples_leaf\" : [3, 5, 8, 15],\n",
    "            \"classification__criterion\" : [\"gini\", \"entropy\"]\n",
    "            }\n",
    "    \n",
    "    clf = GridSearchCV(base_clf,\n",
    "                    param_grid = param,\n",
    "                    scoring = make_scorer(f1_score),\n",
    "                    cv = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=32))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v2.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v2 = constructDT()\n",
    "clf_v2 = load_or_fit(clf_v2, features, labels, \"../impl/dev/clf_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__criterion': 'entropy',\n",
       " 'classification__min_samples_leaf': 15,\n",
       " 'feature_selection__percentile': 30,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.mutual_info_.mutual_info_classif>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38996238565356212"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.732068965517, Precision: 0.284186396936, Recall: 0.6275, F1: 0.381473041664\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v2.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver2(DT)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list_org, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructSVM(base_clf=None, param=None): \n",
    "    \"\"\"\n",
    "    Construct Naive Bayes classifier, define default construction proccess\n",
    "    and deafault grid search setup \n",
    "    \"\"\"    \n",
    "    \n",
    "    if not base_clf:\n",
    "        base_clf = Pipeline([\n",
    "                    ('scaling', MinMaxScaler()),     \n",
    "                    ('feature_selection', SelectPercentile()),\n",
    "                    ('classification', SVC(class_weight=\"balanced\"))\n",
    "                  ])\n",
    "    if not param:\n",
    "        param = {\n",
    "            \"feature_selection__score_func\" : [f_classif, mutual_info_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            \"classification__C\" : np.logspace(-2,2,num=5,endpoint=True),\n",
    "            \"classification__gamma\" : np.logspace(-1,1,num=5,endpoint=True)\n",
    "            }\n",
    "    \n",
    "    clf = GridSearchCV(base_clf,\n",
    "                    param_grid = param,\n",
    "                    scoring = make_scorer(f1_score),\n",
    "                    cv = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=32))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v3.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v3 = constructSVM()\n",
    "clf_v3 = load_or_fit(clf_v3, features, labels, \"../impl/dev/clf_v3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__C': 0.10000000000000001,\n",
       " 'classification__gamma': 10.0,\n",
       " 'feature_selection__percentile': 70,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4198014694993763"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.648620689655, Precision: 0.276362503381, Recall: 0.9, F1: 0.419801469499\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v3.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver3(SVM)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list_org, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructLogReg(base_clf=None, param=None): \n",
    "    \"\"\"\n",
    "    Construct Naive Bayes classifier, define default construction proccess\n",
    "    and deafault grid search setup \n",
    "    \"\"\"    \n",
    "    \n",
    "    if not base_clf:\n",
    "        base_clf = Pipeline([\n",
    "                    ('scaling', MinMaxScaler()),     \n",
    "                    ('feature_selection', SelectPercentile()),\n",
    "                    ('classification', LogisticRegression(class_weight=\"balanced\"))\n",
    "                  ])\n",
    "    if not param:\n",
    "        param = {\n",
    "            \"feature_selection__score_func\" : [f_classif, mutual_info_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            \"classification__C\" : np.logspace(-2,2,num=5,endpoint=True)\n",
    "            }\n",
    "    \n",
    "    clf = GridSearchCV(base_clf,\n",
    "                    param_grid = param,\n",
    "                    scoring = make_scorer(f1_score),\n",
    "                    cv = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=32))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v4.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v4 = constructLogReg()\n",
    "clf_v4 = load_or_fit(clf_v4, features, labels, \"../impl/dev/clf_v4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__C': 0.01,\n",
       " 'feature_selection__percentile': 100,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42037373287262236"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.734482758621, Precision: 0.315266090892, Recall: 0.7, F1: 0.420373732873\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v4.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver4(LogReg)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated on reduced set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v41.pkl\n"
     ]
    }
   ],
   "source": [
    "features_list = [feat for feat in features_list_org if feat not in [\"total_payments\", \"total_stock_value\"]]\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "clf_v41 = constructLogReg()\n",
    "clf_v41 = load_or_fit(clf_v41, features, labels, \"../impl/dev/clf_v41.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__C': 0.01,\n",
       " 'feature_selection__percentile': 100,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v41.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42308613192867461"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v41.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.734827586207, Precision: 0.318005018631, Recall: 0.6975, F1: 0.423086131929\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v41.best_estimator_, my_dataset, features_list)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver41(LogReg)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list_full, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v5.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v5 = constructLogReg()\n",
    "clf_v5 = load_or_fit(clf_v5, features, labels, \"../impl/dev/clf_v5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__C': 0.10000000000000001,\n",
       " 'feature_selection__percentile': 70,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47103806994519054"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76724137931, Precision: 0.363692488067, Recall: 0.725, F1: 0.471038069945\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v5.best_estimator_, my_dataset, features_list_full)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver5(LogReg)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try logistic regression on manually selected list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list_pick = [\n",
    " 'poi',\n",
    " 'bonus',\n",
    " 'deferred_income',\n",
    " 'expenses',\n",
    " 'from_poi_to_this_person_perc',\n",
    " 'from_this_person_to_poi_perc',\n",
    " 'gross_payments',\n",
    " 'long_term_incentive',\n",
    " 'long_term_incentive_perc',\n",
    " 'other',\n",
    " 'restricted_stock',\n",
    " 'salary',\n",
    " 'salary_perc',\n",
    " 'shared_receipt_with_poi',\n",
    " 'shared_receipt_with_poi_perc',\n",
    " 'total_stock_value'\n",
    "]\n",
    "\n",
    "data = featureFormat(my_dataset, features_list_pick, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load fitted classifier\n",
      "Start fitting...\n",
      "Classifier fitted in  6.08 s\n",
      "Fitted classifier was dumped to  ../impl/dev/clf_v6.pkl\n"
     ]
    }
   ],
   "source": [
    "param_lr = {\n",
    "            \"feature_selection__score_func\" : [f_classif],\n",
    "            \"feature_selection__percentile\" : [100],\n",
    "            \"classification__C\" : np.logspace(-2,2,num=5,endpoint=True)\n",
    "            }\n",
    "clf_v6 = constructLogReg(param=param_lr)\n",
    "clf_v6 = load_or_fit(clf_v6, features, labels, \"../impl/dev/clf_v6.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__C': 1.0,\n",
       " 'feature_selection__percentile': 100,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4495104389074977"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772068965517, Precision: 0.353054556555, Recall: 0.67, F1: 0.449510438907\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v6.best_estimator_, my_dataset, features_list_pick)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver6(LogReg)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list_full, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load fitted classifier\n",
      "Start fitting...\n",
      "Classifier fitted in  753.692 s\n",
      "Fitted classifier was dumped to  ../impl/dev/clf_v7.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v7 = constructDT()\n",
    "clf_v7 = load_or_fit(clf_v7, features, labels, \"../impl/dev/clf_v7.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43233605283605281"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.823103448276, Precision: 0.404313492063, Recall: 0.4975, F1: 0.429126567877\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v7.best_estimator_, my_dataset, features_list_full)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver7(DT)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load fitted classifier\n",
      "Start fitting...\n",
      "Classifier fitted in  159.923 s\n",
      "Fitted classifier was dumped to  ../impl/dev/clf_v8.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v8 = constructSVM(param = {\n",
    "            \"feature_selection__score_func\" : [f_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            \"classification__C\" : np.logspace(-2,2,num=5,endpoint=True),\n",
    "            \"classification__gamma\" : np.logspace(-1,1,num=5,endpoint=True)\n",
    "            })\n",
    "clf_v8 = load_or_fit(clf_v8, features, labels, \"../impl/dev/clf_v8.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47911654685184102"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v8.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.817586206897, Precision: 0.417656898657, Recall: 0.615, F1: 0.479116546852\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v8.best_estimator_, my_dataset, features_list_full)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver8(SVM)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression was selected as a final classifier.\n",
    "Next I will analyze feature importance based on coefficients of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feature_selection', SelectPercentile(percentile=70,\n",
       "         score_func=<function f_classif at 0x117394a28>)), ('classification', LogisticRegression(C=0.10000000000000001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list_full, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "final_clf = clf_v5.best_estimator_\n",
    "final_clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_list_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['to_messages', 'shared_receipt_with_poi_perc', 'expenses',\n",
       "       'long_term_incentive', 'from_poi_to_this_person', 'deferred_income',\n",
       "       'shared_receipt_with_poi', 'other', 'bonus_perc',\n",
       "       'long_term_incentive_perc', 'director_fees', 'gross_payments',\n",
       "       'bonus', 'total_stock_value', 'from_this_person_to_poi',\n",
       "       'other_perc', 'restricted_stock', 'salary', 'deferred_income_perc',\n",
       "       'total_payments', 'from_poi_to_this_person_perc',\n",
       "       'exercised_stock_options', 'salary_perc',\n",
       "       'from_this_person_to_poi_perc'], \n",
       "      dtype='|S30')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = np.array(features_list_full[1:])\n",
    "sel_feat = feat[final_clf.named_steps['feature_selection'].get_support()]\n",
    "sel_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bonus_perc', 0.49050521879589942),\n",
       " ('deferred_income', -0.45157412939258657),\n",
       " ('exercised_stock_options', 0.3470091776306421),\n",
       " ('shared_receipt_with_poi_perc', 0.33435054735265907),\n",
       " ('from_this_person_to_poi_perc', 0.32917538230366422),\n",
       " ('long_term_incentive_perc', 0.30285327762752551),\n",
       " ('total_stock_value', 0.29567808814373142),\n",
       " ('expenses', 0.2925797147324109),\n",
       " ('salary', 0.28209926153241111),\n",
       " ('bonus', 0.26818112045952591),\n",
       " ('shared_receipt_with_poi', 0.19122736580832075),\n",
       " ('director_fees', -0.19003692718561885),\n",
       " ('salary_perc', 0.15384040116668052),\n",
       " ('long_term_incentive', 0.14994070178112423),\n",
       " ('other_perc', 0.14711408932559275),\n",
       " ('from_this_person_to_poi', 0.12217186623803525),\n",
       " ('restricted_stock', 0.1042811682825396),\n",
       " ('from_poi_to_this_person', 0.097986278115711825),\n",
       " ('from_poi_to_this_person_perc', 0.08446714298496634),\n",
       " ('gross_payments', 0.081422150985282868),\n",
       " ('total_payments', 0.067987331481177152),\n",
       " ('other', 0.058974615084958257),\n",
       " ('deferred_income_perc', 0.035292922018408855),\n",
       " ('to_messages', 0.018067332048578716)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(sel_feat, *final_clf.named_steps['classification'].coef_), key=lambda s: abs(s[1]) , reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feature_selection', SelectPercentile(percentile=70,\n",
      "         score_func=<function f_classif at 0x117394a28>)), ('classification', LogisticRegression(C=0.10000000000000001, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.75969\tPrecision: 0.33056\tRecall: 0.72400\tF1: 0.45388\tF2: 0.58479\n",
      "\tTotal predictions: 29000\tTrue positives: 2896\tFalse positives: 5865\tFalse negatives: 1104\tTrue negatives: 19135\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7596896551724138, 0.33055587261728114, 0.724)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier(final_clf, my_dataset, features_list_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
