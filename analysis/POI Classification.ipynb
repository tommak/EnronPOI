{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "sys.path.append(\"../impl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data, test_classifier\n",
    "from preprocess import preprocess, ordered_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../impl/final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "my_dataset = preprocess(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset_df = pd.DataFrame.from_dict(my_dataset, orient=\"index\")\n",
    "my_dataset_df.replace('NaN', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclude = [\"poi\", \"email_address\"]\n",
    "all_features_list = [f for f in my_dataset.items()[0][1].keys() if f not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list_org = ['poi'] + ordered_columns + [\"to_messages\", \"from_messages\"]\n",
    "features_list_ext = features_list_org + [\"to_poi_perc\", \"from_poi_perc\", \"shared_with_poi_perc\"]\n",
    "features_list_full = [\"poi\"] + all_features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump cleaned dataset and features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../impl/dev/my_dataset.pkl\", \"w\") as dataset_outfile:\n",
    "        pickle.dump(my_dataset, dataset_outfile)\n",
    "\n",
    "with open(\"../impl/dev/features_list_org.pkl\", \"w\") as featurelist_outfile:\n",
    "        pickle.dump(features_list_org, featurelist_outfile)\n",
    "with open(\"../impl/dev/features_list_ext.pkl\", \"w\") as featurelist_outfile:\n",
    "        pickle.dump(features_list_ext, featurelist_outfile)\n",
    "with open(\"../impl/dev/features_list_full.pkl\", \"w\") as featurelist_outfile:\n",
    "        pickle.dump(features_list_full, featurelist_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.feature_selection import  SelectPercentile, mutual_info_classif, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will consider three different classifiers.\n",
    "Before applying each classifier feature selection procedure is run. Note that parameters of feature selection are tuned along with other classification parameters. \n",
    "100% threshoold in SelectPercentile means that all features are used in classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = features_list_org\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def constructNB(base_clf=None, param=None): \n",
    "    \"\"\"\n",
    "    Construct Naive Bayes classifier, define default construction proccess\n",
    "    and deafault grid search setup \n",
    "    \"\"\"    \n",
    "    \n",
    "    if not base_clf:\n",
    "        base_clf = Pipeline([\n",
    "                    ('feature_selection', SelectPercentile()),\n",
    "                    ('classification', GaussianNB())\n",
    "                  ])\n",
    "    if not param:\n",
    "        param = {\n",
    "            \"feature_selection__score_func\" : [f_classif, mutual_info_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            }\n",
    "    \n",
    "    clf = GridSearchCV(base_clf,\n",
    "                    param_grid = param,\n",
    "                    scoring = make_scorer(f1_score),\n",
    "                    cv = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=32))\n",
    "    return clf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_v1 = constructNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_or_fit(clf, features, labels, path, dump_new=True, features_path=None):\n",
    "    \"\"\"\n",
    "    Load dumped version of classifier from provided path.\n",
    "    Otherwise fit classifier, if dump_new is True, then dump it in a provided path.\n",
    "    If features_path is specified, than dump current features_list to the features_path\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open(path, \"r\") as clf_infile:\n",
    "            fitted_clf = pickle.load(clf_infile)\n",
    "        print \"Classifier was loaded from \", path\n",
    "    except IOError:\n",
    "        print \"Failed to load fitted classifier\\nStart fitting...\"\n",
    "        t0 = time()\n",
    "        fitted_clf = clf\n",
    "        fitted_clf.fit(features, labels)\n",
    "        print \"Classifier fitted in \", round(time()-t0, 3), \"s\"\n",
    "        if dump_new:\n",
    "            with open(path, \"w\") as clf_outfile:\n",
    "                pickle.dump(fitted_clf, clf_outfile)\n",
    "            print \"Fitted classifier was dumped to \", path\n",
    "        \n",
    "    if features_path:\n",
    "        with open(features_path, \"w\") as feat_outfile:\n",
    "            pickle.dump(features_list, feat_outfile)\n",
    "    \n",
    "    return fitted_clf \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_clf(clf, my_dataset, feature_list, n_splits=100, random_state=32, test_size=0.2):\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for train_index, test_index in sss.split(features, labels):\n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_index:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_index:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        clf.fit(features_train, labels_train)\n",
    "        pred = clf.predict(features_test)\n",
    "        accuracy_list.append(accuracy_score(labels_test, pred))\n",
    "        precision_list.append(precision_score(labels_test, pred))\n",
    "        recall_list.append(recall_score(labels_test, pred))\n",
    "        f1_list.append(f1_score(labels_test, pred))\n",
    "\n",
    "    return np.mean(accuracy_list), np.mean(precision_list), np.mean(recall_list), \\\n",
    "            np.mean(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_summary(fname, values, version):\n",
    "    with open(fname, \"a\") as f:\n",
    "        #if empty add header\n",
    "        if f.tell() == 0: \n",
    "            f.write(\"Version, Accuracy, Precision, Recall, F1\\n\")\n",
    "        line = version + \", %2.4f\"*4 % values + \"\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v1 = load_or_fit(clf_v1, features, labels, path=\"../impl/dev/clf_v1.pkl\", \n",
    "                     features_path = \"../impl/dev/features_list_org.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=100, random_state=32, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('feature_selection', SelectPercentile(percentile=10,\n",
       "         score_func=<function f_classif at 0x117790758>)), ('classification', GaussianNB(priors=None))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'feature_selection__score_func': [<function f_classif at 0x117790758>, <function mutual_info_classif at 0x117a74c08>], 'feature_selection__percentile': [30, 50, 70, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(f1_score), verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_selection__percentile': 30,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35413636363636364"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score correspond to best F1 value. Next some other scores are presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850344827586, Precision: 0.44494047619, Recall: 0.33, F1: 0.354136363636\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v1.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentile</th>\n",
       "      <th>score</th>\n",
       "      <th>score_fun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0.354136</td>\n",
       "      <td>&lt;function f_classif at 0x117790758&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.221919</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x117a74c08&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.315711</td>\n",
       "      <td>&lt;function f_classif at 0x117790758&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.236975</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x117a74c08&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0.325613</td>\n",
       "      <td>&lt;function f_classif at 0x117790758&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>0.291190</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x117a74c08&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.316618</td>\n",
       "      <td>&lt;function f_classif at 0x117790758&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>0.316618</td>\n",
       "      <td>&lt;function mutual_info_classif at 0x117a74c08&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  percentile     score                                      score_fun\n",
       "0         30  0.354136            <function f_classif at 0x117790758>\n",
       "1         30  0.221919  <function mutual_info_classif at 0x117a74c08>\n",
       "2         50  0.315711            <function f_classif at 0x117790758>\n",
       "3         50  0.236975  <function mutual_info_classif at 0x117a74c08>\n",
       "4         70  0.325613            <function f_classif at 0x117790758>\n",
       "5         70  0.291190  <function mutual_info_classif at 0x117a74c08>\n",
       "6        100  0.316618            <function f_classif at 0x117790758>\n",
       "7        100  0.316618  <function mutual_info_classif at 0x117a74c08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "{ \"score\" : clf_v1.cv_results_[\"mean_test_score\"], \n",
    "\"percentile\" : clf_v1.cv_results_[\"param_feature_selection__percentile\"],\n",
    "\"score_fun\" : clf_v1.cv_results_['param_feature_selection__score_func']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features were used by NB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exercised_stock_options', 24.815079733218194),\n",
       " ('total_stock_value', 24.182898678566879),\n",
       " ('bonus', 20.792252047181535),\n",
       " ('salary', 18.289684043404513),\n",
       " ('deferred_income', 11.458476579280369)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, pval = f_classif(features, labels)\n",
    "l = zip(features_list_org[1:], f)\n",
    "n_features = int(round(0.3*len(l)))\n",
    "sorted(l, key = lambda s: s[1], reverse=True )[:n_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that NB classifier assumes that featues are independent, however we have included total payments and total stock values along with their constitution. Next we we run NB on reduced set of features and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_list = [feat for feat in features_list_org if feat not in [\"total_payments\", \"total_stock_value\"]]\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "clf_v12 = constructNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v12.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v12 = load_or_fit(clf_v12, features, labels, \"../impl/dev/clf_v12.pkl\", \"dev/features_reduced.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters\n",
      "{'feature_selection__score_func': <function f_classif at 0x117790758>, 'feature_selection__percentile': 70}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best test score\n",
      "0.354200438038\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print \"Optimal parameters\\n{}\\n{}\".format(clf_v12.best_params_, \"-\"*100)\n",
    "print \"Best test score\\n{}\\n{}\".format(clf_v12.best_score_, \"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding correlated features did not change test score, however, we can notice that this time already 70% of features were included in the model. In next section we will try to resrtucture current features or add some new features in order to provide more information for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794482758621, Precision: 0.396085107703, Recall: 0.425, F1: 0.354200438038\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v12.best_estimator_, my_dataset, \n",
    "                                                       features_list)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver12(NB)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for now, Naive Bayes gives nearly 0.35 test score. Both variants have variance and recall higher than 0.3.\n",
    "The second classifier has higher recall - 0.42."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list_org, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructDT(base_clf=None, param=None): \n",
    "    \"\"\"\n",
    "    Construct Naive Bayes classifier, define default construction proccess\n",
    "    and deafault grid search setup \n",
    "    \"\"\"    \n",
    "    \n",
    "    if not base_clf:\n",
    "        base_clf = Pipeline([\n",
    "                    ('feature_selection', SelectPercentile()),\n",
    "                    ('classification', DecisionTreeClassifier(class_weight=\"balanced\"))\n",
    "                  ])\n",
    "    if not param:\n",
    "        param = {\n",
    "            \"feature_selection__score_func\" : [f_classif, mutual_info_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            \"classification__min_samples_leaf\" : [3, 5, 8, 15],\n",
    "            \"classification__criterion\" : [\"gini\", \"entropy\"]\n",
    "            }\n",
    "    \n",
    "    clf = GridSearchCV(base_clf,\n",
    "                    param_grid = param,\n",
    "                    scoring = make_scorer(f1_score),\n",
    "                    cv = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=32))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v2.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v2 = constructDT()\n",
    "clf_v2 = load_or_fit(clf_v2, features, labels, \"../impl/dev/clf_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__criterion': 'entropy',\n",
       " 'classification__min_samples_leaf': 15,\n",
       " 'feature_selection__percentile': 100,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.mutual_info_.mutual_info_classif>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41331916776034427"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.741034482759, Precision: 0.314670204795, Recall: 0.695, F1: 0.418500058765\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v2.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver2(DT)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list_org, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructSVM(base_clf=None, param=None): \n",
    "    \"\"\"\n",
    "    Construct Naive Bayes classifier, define default construction proccess\n",
    "    and deafault grid search setup \n",
    "    \"\"\"    \n",
    "    \n",
    "    if not base_clf:\n",
    "        base_clf = Pipeline([\n",
    "                    ('scaling', MinMaxScaler()),     \n",
    "                    ('feature_selection', SelectPercentile()),\n",
    "                    ('classification', SVC(class_weight=\"balanced\"))\n",
    "                  ])\n",
    "    if not param:\n",
    "        param = {\n",
    "            \"feature_selection__score_func\" : [f_classif, mutual_info_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            \"classification__C\" : np.logspace(-2,2,num=5,endpoint=True),\n",
    "            \"classification__gamma\" : np.logspace(-1,1,num=5,endpoint=True)\n",
    "            }\n",
    "    \n",
    "    clf = GridSearchCV(base_clf,\n",
    "                    param_grid = param,\n",
    "                    scoring = make_scorer(f1_score),\n",
    "                    cv = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=32))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v3.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v3 = constructSVM()\n",
    "clf_v3 = load_or_fit(clf_v3, features, labels, \"../impl/dev/clf_v3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__C': 0.10000000000000001,\n",
       " 'classification__gamma': 10.0,\n",
       " 'feature_selection__percentile': 30,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40470640812799907"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.660689655172, Precision: 0.264783136712, Recall: 0.79, F1: 0.390650660504\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v3.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver3(SVM)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list_org, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructLogReg(base_clf=None, param=None): \n",
    "    \"\"\"\n",
    "    Construct Naive Bayes classifier, define default construction proccess\n",
    "    and deafault grid search setup \n",
    "    \"\"\"    \n",
    "    \n",
    "    if not base_clf:\n",
    "        base_clf = Pipeline([\n",
    "                    ('scaling', MinMaxScaler()),     \n",
    "                    ('feature_selection', SelectPercentile()),\n",
    "                    ('classification', LogisticRegression(class_weight=\"balanced\"))\n",
    "                  ])\n",
    "    if not param:\n",
    "        param = {\n",
    "            \"feature_selection__score_func\" : [f_classif, mutual_info_classif],\n",
    "            \"feature_selection__percentile\" : [30, 50, 70, 100],\n",
    "            \"classification__C\" : np.logspace(-2,2,num=5,endpoint=True)\n",
    "            }\n",
    "    \n",
    "    clf = GridSearchCV(base_clf,\n",
    "                    param_grid = param,\n",
    "                    scoring = make_scorer(f1_score),\n",
    "                    cv = StratifiedShuffleSplit(n_splits=100, test_size=0.2, random_state=32))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v4.pkl\n"
     ]
    }
   ],
   "source": [
    "clf_v4 = constructLogReg()\n",
    "clf_v4 = load_or_fit(clf_v4, features, labels, \"../impl/dev/clf_v4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__C': 0.10000000000000001,\n",
       " 'feature_selection__percentile': 50,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.mutual_info_.mutual_info_classif>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40310758754489395"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.724827586207, Precision: 0.300125976148, Recall: 0.6575, F1: 0.391908545101\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v4.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver4(LogReg)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated on reduced set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was loaded from  ../impl/dev/clf_v41.pkl\n"
     ]
    }
   ],
   "source": [
    "features_list = [feat for feat in features_list_org if feat not in [\"total_payments\", \"total_stock_value\"]]\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "clf_v41 = constructLogReg()\n",
    "clf_v41 = load_or_fit(clf_v41, features, labels, \"../impl/dev/clf_v41.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__C': 0.10000000000000001,\n",
       " 'feature_selection__percentile': 30,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection.mutual_info_.mutual_info_classif>}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v41.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40310758754489395"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.715862068966, Precision: 0.293816487434, Recall: 0.6475, F1: 0.384401632853\n"
     ]
    }
   ],
   "source": [
    "scores = test_clf(clf_v41.best_estimator_, my_dataset, features_list_org)\n",
    "print \"Accuracy: {}, Precision: {}, Recall: {}, F1: {}\".format(*scores)\n",
    "add_summary(\"../impl/dev/summary.csv\",scores, \"ver41(LogReg)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: Add new features, run Logistic Regression and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TO DO: Draw decision tree\n",
    "\n",
    "# from IPython.display import Image\n",
    "\n",
    "# export_graphviz(clf_v2.best_estimator_, \"tree.dot\", feature_names=features_list_org[1:],  \n",
    "#                 class_names = [\"Not POI\", \"POI\"])\n",
    "# ! dot -Tpng tree.dot > tree.png\n",
    "# Image(filename=\"tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: Show summury of all runs. Select classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
